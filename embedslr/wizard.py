"""
Interaktywny kreatorÂ EmbedSLR 
Uruchom:  $ embedslr-wizard

"""
from __future__ import annotations
import os, sys, zipfile, shutil, tempfile, textwrap, datetime as dt
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

from .embeddings import list_models, get_embeddings

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  1.  Pobranie danych wejÅ›ciowych                     â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
print("ğŸ“¦  ÅšcieÅ¼ka do pliku CSV ze Scopus/WoS:")
csv_path = Path(input(">> ").strip()).expanduser()
if not csv_path.exists():
    sys.exit(f"âŒ  Nie znaleziono pliku: {csv_path}")

df = pd.read_csv(csv_path, low_memory=False)
print(f"âœ…  ZaÅ‚adowano {len(df)} rekordÃ³w, kolumny: {list(df.columns)[:8]}...")

query = input("â“  Podaj problem badawczy / query:\n>> ").strip()

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  2.  WybÃ³r providera iÂ modelu                       â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
prov_list = list(list_models().keys())
print("\nğŸ“œ  DostÄ™pni providerzy:", prov_list)
provider = input(f"Provider [default={prov_list[0]}]: ").strip() or prov_list[0]

models = list_models()[provider]
print(f"\nğŸ“œ  Modele dla {provider}  (pierwszeÂ 20):")
for i, m in enumerate(models[:20], 1):
    print(f"  {i:2d}. {m}")
model = input("Model [ENTER = 1â€‘szy zÂ listy lub dowolna nazwa]: ").strip() or models[0]

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  3.  Topâ€‘N +Â kluczeÂ API                             â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
try:
    topN = int(input("ğŸ”¢  Topâ€‘N publikacji doÂ analizy bibliometrycznej [ENTER = wszystkie]: ") or 0)
except ValueError:
    topN = 0

need_key = provider in {"openai", "cohere", "nomic", "jina"}
if need_key and not os.getenv(f"{provider.upper()}_API_KEY"):
    key = input(f"ğŸ”‘  Podaj {provider.upper()}_API_KEY (ENTER = pomiÅ„): ").strip()
    if key:
        os.environ[f"{provider.upper()}_API_KEY"] = key

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  4.  Przygotowanie tekstÃ³w                          â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
title_col = next((c for c in ('Article Title', 'Title', 'TI') if c in df.columns), None)
abstr_col = next((c for c in ('Abstract', 'AB') if c in df.columns), None)
if not title_col:
    sys.exit("âŒ  Nie znaleziono kolumny zÂ tytuÅ‚em (Title).")

df["combined_text"] = (
    df[title_col].fillna("").astype(str) + " " +
    (df[abstr_col].fillna("").astype(str) if abstr_col else "")
)

texts = df["combined_text"].tolist()

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  5.  Embeddingi iÂ distance_cosine                   â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
print("\nâ³  LiczÄ™ embedding dla zapytaniaâ€¦")
emb_q = np.array(get_embeddings([query], provider=provider, model=model)[0])

print("â³  LiczÄ™ embeddingi dla artykuÅ‚Ã³wâ€¦")
emb_a = np.array(get_embeddings(texts, provider=provider, model=model))

dist = 1 - cosine_similarity([emb_q], emb_a)[0]
df["distance_cosine"] = dist
df_sorted = df.sort_values("distance_cosine")

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  6.  Topâ€‘N iÂ zapis CSV                              â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
out_dir = Path.cwd()
sorted_csv = out_dir / "articles_sorted_by_distance.csv"
df_sorted.to_csv(sorted_csv, index=False)
print(f"ğŸ“„  Zapisano {sorted_csv}")

if topN and topN < len(df_sorted):
    df_top = df_sorted.head(topN)
else:
    df_top = df_sorted
top_csv = out_dir / "topN_for_metrics.csv"
df_top.to_csv(top_csv, index=False)
print(f"ğŸ“„  Zapisano {top_csv}")

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  7.  Bibliometrics (8Â wskaÅºnikÃ³w)                   â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
try:
    from embedslr.metrics import compute_metrics  # istnieje wÂ repo
except ImportError:
    # fallback â€“ wklejone krÃ³tkie podsumowanie sÅ‚Ã³w kluczowych
    def compute_metrics(df_in: pd.DataFrame) -> dict[str, float | int]:
        kws = df_in.get("Author Keywords", pd.Series(dtype=str)).fillna("")
        kws = kws.str.split(";").explode().str.lower().str.strip()
        total_pairs = len(df_in) * (len(df_in) - 1) // 2
        return {
            "avg_common_keywords": kws.value_counts().gt(1).sum() / max(total_pairs, 1),
            "keywords_>=2_articles": kws.value_counts().gt(1).sum(),
        }

metrics = compute_metrics(df_top)
report_path = out_dir / "biblio_report.txt"
with report_path.open("w", encoding="utf-8") as f:
    f.write("==== BIBLIOMETRIC REPORT ====\n")
    for k, v in metrics.items():
        f.write(f"{k:<35}: {v}\n")
print(f"ğŸ“„  Zapisano {report_path}")

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚  8.  ZIPâ€‘pakiet doÂ pobrania                         â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
zip_path = out_dir / "embedslr_results.zip"
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
    for p in (sorted_csv, top_csv, report_path):
        z.write(p, arcname=p.name)
print(f"ğŸ  Gotowe â€“Â {zip_path}")

print("\nâœ”ï¸  KONIEC.  Pliki znajdziesz wÂ bieÅ¼Ä…cym katalogu.")
